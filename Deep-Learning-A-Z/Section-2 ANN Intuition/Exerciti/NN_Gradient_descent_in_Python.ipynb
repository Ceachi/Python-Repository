{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: https://iamtrask.github.io/2015/07/27/python-network-part2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16595599]\n",
      " [ 0.44064899]]\n",
      "Output After Training:\n",
      "[[0.00505119]\n",
      " [0.00505119]\n",
      " [0.99494905]\n",
      " [0.99494905]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# compute sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# convert output of sigmoid function to its derivative\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)\n",
    "    \n",
    "# input dataset\n",
    "X = np.array([  [0,1],\n",
    "                [0,1],\n",
    "                [1,0],\n",
    "                [1,0] ])\n",
    "    \n",
    "# output dataset            \n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "synapse_0 = 2*np.random.random((2,1)) - 1\n",
    "\n",
    "print(synapse_0)\n",
    "\n",
    "for iter in range(10000):\n",
    "\n",
    "    # forward propagation\n",
    "    layer_0 = X\n",
    "    layer_1 = sigmoid(np.dot(layer_0,synapse_0))\n",
    "\n",
    "    # how much did we miss?\n",
    "    layer_1_error = layer_1 - y\n",
    "\n",
    "    # multiply how much we missed by the \n",
    "    # slope of the sigmoid at the values in l1\n",
    "    layer_1_delta = layer_1_error * sigmoid_output_to_derivative(layer_1)\n",
    "    synapse_0_derivative = np.dot(layer_0.T,layer_1_delta)\n",
    "\n",
    "    # update weights\n",
    "    synapse_0 -= synapse_0_derivative\n",
    "\n",
    "print (\"Output After Training:\")\n",
    "print (layer_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving our Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training With Alpha:0.001\n",
      "Error after 0 iterations:0.49641003190272537\n",
      "Error after 10000 iterations:0.49516402549338606\n",
      "Error after 20000 iterations:0.4935960431880486\n",
      "Error after 30000 iterations:0.4916063585594306\n",
      "Error after 40000 iterations:0.48910016654420474\n",
      "Error after 50000 iterations:0.48597785784615843\n",
      "\n",
      "Training With Alpha:0.01\n",
      "Error after 0 iterations:0.49641003190272537\n",
      "Error after 10000 iterations:0.45743107444190134\n",
      "Error after 20000 iterations:0.359097202563399\n",
      "Error after 30000 iterations:0.23935813715897253\n",
      "Error after 40000 iterations:0.1430706590133703\n",
      "Error after 50000 iterations:0.09859642980892719\n",
      "\n",
      "Training With Alpha:0.1\n",
      "Error after 0 iterations:0.49641003190272537\n",
      "Error after 10000 iterations:0.042888017000115755\n",
      "Error after 20000 iterations:0.02409899422852161\n",
      "Error after 30000 iterations:0.018110652146797843\n",
      "Error after 40000 iterations:0.014987616272210912\n",
      "Error after 50000 iterations:0.013014490538142586\n",
      "\n",
      "Training With Alpha:1\n",
      "Error after 0 iterations:0.49641003190272537\n",
      "Error after 10000 iterations:0.008584525653247159\n",
      "Error after 20000 iterations:0.0057894598625078085\n",
      "Error after 30000 iterations:0.004629176776769985\n",
      "Error after 40000 iterations:0.003958765280273649\n",
      "Error after 50000 iterations:0.0035101225678616766\n",
      "\n",
      "Training With Alpha:10\n",
      "Error after 0 iterations:0.49641003190272537\n",
      "Error after 10000 iterations:0.003129388763011837\n",
      "Error after 20000 iterations:0.002144595579852179\n",
      "Error after 30000 iterations:0.0017239754995622308\n",
      "Error after 40000 iterations:0.0014782145122908034\n",
      "Error after 50000 iterations:0.0013127406283356764\n",
      "\n",
      "Training With Alpha:100\n",
      "Error after 0 iterations:0.49641003190272537\n",
      "Error after 10000 iterations:0.12547698383358538\n",
      "Error after 20000 iterations:0.12533033354043677\n",
      "Error after 30000 iterations:0.12526772879373652\n",
      "Error after 40000 iterations:0.12523107370012884\n",
      "Error after 50000 iterations:0.12520635280373757\n",
      "\n",
      "Training With Alpha:1000\n",
      "Error after 0 iterations:0.49641003190272537\n",
      "Error after 10000 iterations:0.5\n",
      "Error after 20000 iterations:0.5\n",
      "Error after 30000 iterations:0.5\n",
      "Error after 40000 iterations:0.5\n",
      "Error after 50000 iterations:0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "alphas = [0.001,0.01,0.1,1,10,100,1000]\n",
    "\n",
    "# compute sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# convert output of sigmoid function to its derivative\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)\n",
    "    \n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "\t\t\t[1],\n",
    "\t\t\t[1],\n",
    "\t\t\t[0]])\n",
    "\n",
    "for alpha in alphas:\n",
    "    print (\"\\nTraining With Alpha:\" + str(alpha))\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # randomly initialize our weights with mean 0\n",
    "    synapse_0 = 2*np.random.random((3,4)) - 1\n",
    "    synapse_1 = 2*np.random.random((4,1)) - 1\n",
    "\n",
    "    for j in range(60000):\n",
    "\n",
    "        # Feed forward through layers 0, 1, and 2\n",
    "        layer_0 = X\n",
    "        layer_1 = sigmoid(np.dot(layer_0,synapse_0))\n",
    "        layer_2 = sigmoid(np.dot(layer_1,synapse_1))\n",
    "\n",
    "        # how much did we miss the target value?\n",
    "        layer_2_error = layer_2 - y\n",
    "\n",
    "        if (j% 10000) == 0:\n",
    "            print (\"Error after \"+str(j)+\" iterations:\" + str(np.mean(np.abs(layer_2_error))))\n",
    "\n",
    "        # in what direction is the target value?\n",
    "        # were we really sure? if so, don't change too much.\n",
    "        layer_2_delta = layer_2_error*sigmoid_output_to_derivative(layer_2)\n",
    "\n",
    "        # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
    "        layer_1_error = layer_2_delta.dot(synapse_1.T)\n",
    "\n",
    "        # in what direction is the target l1?\n",
    "        # were we really sure? if so, don't change too much.\n",
    "        layer_1_delta = layer_1_error * sigmoid_output_to_derivative(layer_1)\n",
    "\n",
    "        synapse_1 -= alpha * (layer_1.T.dot(layer_2_delta))\n",
    "        synapse_0 -= alpha * (layer_0.T.dot(layer_1_delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
